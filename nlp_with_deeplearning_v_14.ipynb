{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRmLDVqfZA9JdBl4b8MEhp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moni8210/Assignment-3/blob/main/nlp_with_deeplearning_v_14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVuzi-oWnY8p",
        "outputId": "8e4292f5-492b-4b3c-d51b-2bc4856b7c94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2 3 4 1]\n",
            " [5 1 6 7]]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Sample data\n",
        "texts = [\"I love machine learning\", \"Deep learning is amazing\"]\n",
        "\n",
        "# Tokenization: Convert words to numbers\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "# Padding: Make sequences the same length\n",
        "padded_sequences = pad_sequences(sequences, padding='post')\n",
        "\n",
        "print(padded_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=1000, output_dim=64))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_PYhUu7E05G",
        "outputId": "a4d0ea7f-d980-4d57-ee03-9dc3c25d0e63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 64)          64000     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                33024     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 97089 (379.25 KB)\n",
            "Trainable params: 97089 (379.25 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume X_train, y_train, X_val, y_val are defined\n",
        "# Assume X_train, y_train, X_val, y_val are defined\n",
        "import numpy as np\n",
        "y_train = np.array(y_train) # Convert y_train to a NumPy array\n",
        "y_val = np.array(y_val) # Convert y_val to a NumPy array\n",
        "\n",
        "model.fit(X_train, y_train, epochs=5, validation_data=(X_val, y_val))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wroJb3xjE1KU",
        "outputId": "ce099bb8-714f-424a-b707-2f4538d35484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.6931 - accuracy: 0.6667 - val_loss: 0.6937 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6882 - accuracy: 0.6667 - val_loss: 0.6963 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6832 - accuracy: 0.6667 - val_loss: 0.6988 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6782 - accuracy: 0.6667 - val_loss: 0.7015 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6731 - accuracy: 0.6667 - val_loss: 0.7043 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d91adad5330>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_val, y_val)\n",
        "print(f'Validation Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6NHbQIeE1Yr",
        "outputId": "c5e12897-4eb9-41de-a0ea-9984a9d54c8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step - loss: 0.7043 - accuracy: 0.0000e+00\n",
            "Validation Accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the old text data\n",
        "predictions = model.predict(padded_sequences)\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovwK-nngE1nE",
        "outputId": "76d2e727-257b-49e5-ba0e-9c67a283b3ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 424ms/step\n",
            "[[0.49574393]\n",
            " [0.49447405]\n",
            " [0.47986504]\n",
            " [0.47686788]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(\"Natural language processing with spaCy is easy!\")\n",
        "for token in doc:\n",
        "    print(token.text, token.pos_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBDPJRfME1y1",
        "outputId": "115bee30-fe6a-47ed-b429-2a8267354edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural ADJ\n",
            "language NOUN\n",
            "processing NOUN\n",
            "with ADP\n",
            "spaCy PROPN\n",
            "is AUX\n",
            "easy ADJ\n",
            "! PUNCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "# Load the dataset\n",
        "newsgroups_train = fetch_20newsgroups(subset='train')\n",
        "print(newsgroups_train.data[:2])  # Print the first two posts\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZgNY6tiE12F",
        "outputId": "17be913d-d9fe-4baf-8a0a-9d6be74a877c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\", \"From: guykuo@carson.u.washington.edu (Guy Kuo)\\nSubject: SI Clock Poll - Final Call\\nSummary: Final call for SI clock reports\\nKeywords: SI,acceleration,clock,upgrade\\nArticle-I.D.: shelley.1qvfo9INNc3s\\nOrganization: University of Washington\\nLines: 11\\nNNTP-Posting-Host: carson.u.washington.edu\\n\\nA fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.\\n\\nGuy Kuo <guykuo@u.washington.edu>\\n\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dBaJ4ODUE2Fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-DTxDwuhE2I8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}